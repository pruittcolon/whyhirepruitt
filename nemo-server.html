<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>NeMo AI Ecosystem ‚Ä¢ Pruitt Colon</title>
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;600;800&family=Inter:wght@400;600&display=swap" rel="stylesheet"/>
  <script src="https://cdn.jsdelivr.net/npm/tsparticles@2/tsparticles.bundle.min.js"></script>
  <script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ 
      startOnLoad: true,
      theme: 'dark',
      themeVariables: {
        primaryColor: '#00aaff',
        primaryTextColor: '#f0f6ff',
        primaryBorderColor: '#00aaff',
        lineColor: '#00aaff',
        secondaryColor: '#0f1219',
        tertiaryColor: '#1a1f2e'
      }
    });
  </script>
  <style>
    :root {
      --bg-1: #0c0e11;
      --bg-2: #0f1219;
      --accent: #00aaff;
      --accent-glow: rgba(0, 170, 255, 0.4);
      --text: #f0f6ff;
      --card-bg: rgba(255,255,255,0.07);
      --card-border: rgba(255,255,255,0.18);
      --radius: 1rem;
      --shadow: 0 0 20px rgba(0,170,255,0.28);
      --transition: all .3s ease;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: "Inter", sans-serif;
      background: linear-gradient(130deg, var(--bg-1) 0%, var(--bg-2) 100%);
      background-size: 200% 200%;
      animation: gradientBG 12s ease infinite;
      color: var(--text);
      overflow-x: hidden;
      font-size: 18px;
      line-height: 1.8;
    }
    @keyframes gradientBG {
      0%   { background-position: 0 50%; }
      50%  { background-position: 100% 50%; }
      100% { background-position: 0 50%; }
    }
    body.nav-open { overflow: hidden; }
  /* Particles background container (behind all content) */
  #particles-js { position: fixed; inset: 0; z-index: -1; pointer-events: none; }
    
    /* NAV */
    nav {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      padding: 1rem 3rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      backdrop-filter: blur(12px);
      background: rgba(0,0,0,0.25);
      border-bottom: 1px solid rgba(255,255,255,0.06);
      transition: var(--transition);
      z-index: 1000;
    }
    nav.scrolled { padding: .6rem 3rem; background: rgba(0,0,0,0.55); }
    .brand { font-family: "Orbitron", sans-serif; font-weight: 800; font-size: 1.2rem; letter-spacing: .03em; }
    .nav-links { list-style: none; display: flex; gap: 2rem; }
    .nav-links a { color: var(--text); font-weight: 600; text-decoration: none; position: relative; }
    .nav-links a::after { content: ""; position: absolute; left: 0; bottom: -4px; width: 0; height: 2px; background: var(--accent); transition: var(--transition); }
    .nav-links a:hover::after { width: 100%; }
    .menu-toggle { display: none; background: none; border: none; font-size: 1.8rem; color: var(--text); cursor: pointer; }
    
    @media (max-width: 720px) {
      .menu-toggle { display: block; }
      .nav-links {
        position: absolute;
        top: 100%;
        left: 0;
        right: 0;
        flex-direction: column;
        background: rgba(0,0,0,0.92);
        padding: 1.4rem 3rem;
        gap: 1.2rem;
        transform: translateY(-120%);
        opacity: 0;
        pointer-events: none;
        transition: var(--transition);
      }
      .nav-links.open { transform: translateY(0); opacity: 1; pointer-events: auto; }
    }
    
    /* WRAPPER */
    .wrapper { width: 90%; max-width: 1200px; margin: 5rem auto 0 auto; animation: fadeIn .5s both; }
    @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
    
    /* HERO */
    .hero {
      text-align: center;
      margin-bottom: 3rem;
      padding: 2rem;
      background: linear-gradient(135deg, rgba(0,170,255,0.1), rgba(0,170,255,0.05));
      border-radius: var(--radius);
      border: 2px solid var(--accent);
      box-shadow: 0 0 40px var(--accent-glow);
    }
    .hero h1 {
      font-family: "Orbitron", sans-serif;
      font-size: clamp(2rem, 5vw, 3.5rem);
      color: var(--accent);
      margin-bottom: 1rem;
      text-shadow: 0 0 20px var(--accent-glow);
    }
    .hero .subtitle {
      font-size: clamp(1.15rem, 2.5vw, 1.5rem);
      margin-bottom: 1rem;
      line-height: 1.7;
      opacity: 0.95;
    }
    .hero .value-prop {
      font-size: clamp(1.05rem, 2vw, 1.3rem);
      font-style: italic;
      margin-bottom: 1.5rem;
      color: var(--accent);
    }
    .badge-row {
      display: flex;
      justify-content: center;
      gap: 1rem;
      flex-wrap: wrap;
      margin: 1.5rem 0;
    }
    .badge {
      display: inline-block;
      padding: 0.6rem 1.2rem;
      background: rgba(0,170,255,0.15);
      border: 1px solid var(--accent);
      border-radius: 2rem;
      font-size: 1rem;
      font-weight: 600;
    }
    .cta-row {
      display: flex;
      justify-content: center;
      gap: 1.5rem;
      margin-top: 1.5rem;
      flex-wrap: wrap;
    }
    .btn-primary {
      display: inline-block;
      padding: 0.9rem 2rem;
      background: var(--accent);
      color: #000;
      font-weight: 700;
      border-radius: var(--radius);
      text-decoration: none;
      transition: var(--transition);
      box-shadow: 0 0 15px var(--accent-glow);
    }
    .btn-primary:hover {
      background: #0088dd;
      box-shadow: 0 0 25px var(--accent-glow);
      transform: translateY(-2px);
    }
    .btn-secondary {
      display: inline-block;
      padding: 0.9rem 2rem;
      background: transparent;
      color: var(--accent);
      font-weight: 700;
      border: 2px solid var(--accent);
      border-radius: var(--radius);
      text-decoration: none;
      transition: var(--transition);
    }
    .btn-secondary:hover {
      background: var(--accent);
      color: #000;
      box-shadow: 0 0 15px var(--accent-glow);
    }
    
    /* CARDS */
    .card {
      background: var(--card-bg);
      backdrop-filter: blur(8px);
      border: 1px solid var(--card-border);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      padding: 2rem;
      margin-bottom: 2.5rem;
      transition: var(--transition);
    }
    .card:hover {
      box-shadow: 0 12px 40px rgba(0,170,255,0.3);
      transform: translateY(-3px);
    }
    .card h2 {
      font-family: "Orbitron", sans-serif;
      color: var(--accent);
      font-size: clamp(1.5rem, 3vw, 2rem);
      margin-bottom: 1rem;
      text-shadow: 0 0 10px var(--accent-glow);
    }
    .card h3 {
      color: var(--accent);
      font-size: 1.3rem;
      margin: 1.5rem 0 0.8rem 0;
      font-family: "Orbitron", sans-serif;
    }
    .card p, .card li {
      line-height: 1.8;
      margin-bottom: 1.2rem;
      font-size: 1.1rem;
    }
    .card ul {
      list-style: disc;
      margin-left: 1.5rem;
    }
    
    /* TECH STACK GRID */
    .tech-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 1.5rem;
      margin-top: 1.5rem;
    }
    .tech-item {
      background: rgba(0,170,255,0.08);
      padding: 1rem;
      border-radius: 0.5rem;
      border: 1px solid rgba(0,170,255,0.3);
    }
    .tech-item h4 {
      color: var(--accent);
      font-size: 1.2rem;
      margin-bottom: 0.7rem;
      font-weight: 600;
    }
    .tech-item p {
      font-size: 1.05rem;
      margin-bottom: 0;
      line-height: 1.6;
    }
    
    /* FEATURE CARDS */
    .features {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 1.5rem;
      margin-top: 1.5rem;
    }
    .feature-card {
      background: var(--card-bg);
      border: 1px solid var(--card-border);
      border-radius: var(--radius);
      padding: 1.5rem;
      cursor: pointer;
      transition: var(--transition);
    }
    .feature-card:hover {
      border-color: var(--accent);
      box-shadow: 0 0 20px var(--accent-glow);
      transform: translateY(-3px);
    }
    .feature-card h3 {
      margin-top: 0;
      font-size: 1.3rem;
    }
    .feature-card p {
      font-size: 1.05rem;
    }
    .feature-card .detail {
      display: none;
      margin-top: 1rem;
      padding-top: 1rem;
      border-top: 1px solid rgba(255,255,255,0.1);
      font-size: 1.1rem;
      line-height: 1.75;
    }
    .feature-card.expanded .detail {
      display: block;
      animation: fadeIn 0.3s ease;
    }
    
    /* CODE BLOCK */
    pre {
      background: rgba(0,0,0,0.5);
      border: 1px solid rgba(0,170,255,0.3);
      border-radius: 0.5rem;
      padding: 1.5rem;
      overflow-x: auto;
      margin: 1.5rem 0;
    }
    code {
      color: #7cff9c;
      font-family: "Courier New", monospace;
      font-size: 1rem;
      line-height: 1.7;
    }
    .comment { color: #999; }
    
    /* MERMAID DIAGRAMS */
    .mermaid {
      background: rgba(0,0,0,0.3);
      border-radius: var(--radius);
      padding: 2rem;
      margin: 2rem 0;
      overflow-x: auto;
      max-width: 100%;
    }
    .mermaid svg {
      max-width: 100%;
      height: auto;
    }
    @media (max-width: 768px) {
      .mermaid {
        padding: 1rem;
        font-size: 0.8rem;
      }
    }
    
    /* ECOSYSTEM FLOW */
    .ecosystem-flow {
      display: flex;
      flex-direction: column;
      gap: 1rem;
      margin: 2rem 0;
    }
    .flow-step {
      display: flex;
      align-items: center;
      gap: 1.2rem;
      padding: 1.2rem;
      background: rgba(0,170,255,0.1);
      border-left: 4px solid var(--accent);
      border-radius: 0.5rem;
    }
    .flow-step .num {
      font-size: 1.8rem;
      font-weight: 800;
      color: var(--accent);
      min-width: 50px;
    }
    .flow-step strong {
      font-size: 1.15rem;
    }
    .flow-step div {
      font-size: 1.08rem;
      line-height: 1.7;
    }
    
    footer {
      text-align: center;
      padding: 2rem 0;
      margin-top: 3rem;
      color: #aaa;
      font-size: 0.9rem;
    }
    
    /* MOBILE OPTIMIZATIONS */
    @media (max-width: 768px) {
      body { font-size: 16px; }
      .wrapper { width: 95%; }
      .hero { padding: 1.5rem 1rem; }
      .hero h1 { font-size: 2rem; }
      .hero .subtitle { font-size: 1.1rem; }
      .hero .value-prop { font-size: 1rem; }
      .badge-row { gap: 0.5rem; }
      .badge { padding: 0.5rem 1rem; font-size: 0.95rem; }
      .cta-row { flex-direction: column; gap: 1rem; }
      .btn-primary, .btn-secondary { 
        width: 100%; 
        text-align: center;
        padding: 1rem 2rem;
        font-size: 1.05rem;
      }
      .card { padding: 1.5rem; }
      .card h2 { font-size: 1.6rem; }
      .card h3 { font-size: 1.25rem; }
      .card p, .card li { font-size: 1.05rem; }
      .tech-grid { grid-template-columns: 1fr; gap: 1rem; }
      .features { grid-template-columns: 1fr; }
      .flow-step { flex-direction: column; text-align: left; align-items: flex-start; }
      .flow-step .num { font-size: 1.5rem; }
      .flow-step div { font-size: 1.05rem; }
      pre { padding: 1rem; overflow-x: auto; }
      code { font-size: 0.9rem; }
      nav { padding: 1rem 1.5rem; }
      .brand { font-size: 1.1rem; }
    }
  </style>
</head>
<body>
  <div id="particles-js"></div>
  
  <nav id="navbar">
    <div class="brand">Pruitt Colon</div>
    <button class="menu-toggle" id="menu-toggle" aria-label="Open navigation" aria-expanded="false" aria-controls="nav-links">‚ò∞</button>
    <ul class="nav-links" id="nav-links">
      <li><a href="index.html">Home</a></li>
      <li><a href="nemo-server.html">Showcase</a></li>
      <li><a href="about.html">About</a></li>
      <li><a href="resume.html">Resume</a></li>
      <li><a href="skills.html">Skills</a></li>
      <li><a href="projects.html">Projects</a></li>
      <li><a href="contact.html">Contact</a></li>
    </ul>
  </nav>

  <div class="wrapper">
    <!-- HERO -->
    <section class="hero">
      <h1>NeMo AI Ecosystem</h1>
      <p class="subtitle">Complete Voice-Controlled Life Automation System<br/>
      Enterprise AI + AR Glasses + IoT Hub + Smart Home Integration</p>
      <p class="value-prop">"From voice command to smart home action in milliseconds"</p>
      
      <div class="badge-row">
        <span class="badge">6 Microservices</span>
        <span class="badge">Python 3.12</span>
        <span class="badge">Docker Compose</span>
        <span class="badge">GPU Coordination</span>
        <span class="badge">Enterprise-Grade</span>
      </div>
      
      <div class="cta-row">
        <a href="https://github.com/pruittcolon/NeMo_Server" target="_blank" class="btn-primary">View on GitHub ‚Üí</a>
        <a href="#architecture" class="btn-secondary">See Architecture</a>
      </div>
    </section>

    <!-- EXECUTIVE SUMMARY -->
    <div class="card">
      <h2>Executive Summary</h2>
      <p><strong>This is a production-ready distributed microservices platform for conversational AI.</strong></p>
      <p>The NeMo Server implements a sophisticated microservices architecture with 6 independent services orchestrated via Docker Compose. Features intelligent GPU coordination, Redis pub/sub messaging, PostgreSQL task queuing, and multi-layer security. Integrates AR wearables, mobile apps, IoT devices, and cloud APIs into a unified voice-controlled automation system.</p>
      
      <h3>Technical Value Proposition</h3>
      <ul>
        <li><strong>Distributed Architecture:</strong> 6 microservices (API Gateway, Transcription, Gemma AI, RAG, Emotion, GPU Coordinator) with service isolation and independent scaling</li>
        <li><strong>Intelligent GPU Sharing:</strong> Pause/resume protocol managed by dedicated GPU Coordinator service via Redis Pub/Sub - enables single-GPU systems to run both ASR and LLM</li>
        <li><strong>Enterprise Patterns:</strong> Service-to-service JWT authentication, defense-in-depth security, encrypted databases (SQLCipher), audit logging, health checks</li>
        <li><strong>Production Infrastructure:</strong> Docker Compose orchestration, Redis coordination, PostgreSQL task queue, FAISS vector search, multi-stage builds with CUDA 12.6+</li>
        <li><strong>Real-World Integration:</strong> AR glasses (Even Reality), Flutter mobile app, IoT hub, VoiceMonkey/Alexa, Deepgram/OpenAI fallback APIs</li>
      </ul>
    </div>

    <!-- ARCHITECTURE DIAGRAMS -->
    <div class="card" id="architecture">
      <h2>System Architecture</h2>
      <p>Three complementary views of the NeMo Server architecture</p>
      
      <h3 style="color: var(--accent); margin-top: 2rem;">User Architecture - Client to Container</h3>
      <p>Complete user journey from AR glasses through frontend to backend containers</p>
      <div class="mermaid">
graph TB
    User[üë§ User]
    
    subgraph Layer1["ü•Ω Layer 1: Client Devices"]
        Glasses[Even Reality AR Glasses<br/>G1 Hardware]
        Mobile[Android Device<br/>Flutter App]
        Browser[Web Browser<br/>Desktop/Mobile]
    end
    
    subgraph Layer2["üì± Layer 2: Frontend Applications"]
        EvenApp[Even Demo App<br/>Kotlin/JNI]
        FlutterUI[Flutter Mobile UI<br/>Dart + Assets]
        WebUI[HTML/CSS/JS Frontend<br/>Static Files]
    end
    
    subgraph Layer3["üåê Layer 3: API Gateway Container"]
        Gateway[API Gateway :8000<br/>FastAPI<br/>Authentication<br/>Request Routing]
    end
    
    subgraph Layer4["üê≥ Layer 4: Microservice Containers"]
        Transcription[Transcription :8003<br/>Docker Container<br/>NeMo + TitaNet]
        Gemma[Gemma AI :8001<br/>Docker Container<br/>llama.cpp]
        RAG[RAG :8004<br/>Docker Container<br/>FAISS + Embeddings]
        Emotion[Emotion :8005<br/>Docker Container<br/>DistilRoBERTa]
        Coordinator[GPU Coordinator :8002<br/>Docker Container<br/>Redis + PostgreSQL]
    end
    
    subgraph Layer5["ÔøΩÔ∏è Layer 5: Data & Infrastructure"]
        Redis[(Redis Container<br/>Pub/Sub)]
        Postgres[(PostgreSQL Container<br/>Task Queue)]
        Volumes[Volume Mounts<br/>users.db<br/>rag.db<br/>faiss_index/<br/>models/]
    end
    
    User --> Layer1 --> Layer2 --> Layer3 --> Layer4 --> Layer5
    
    Glasses -.-> EvenApp
    Mobile -.-> FlutterUI
    Browser -.-> WebUI
    
    style Layer1 fill:#aa96da,color:#fff,stroke:#fff,stroke-width:2px
    style Layer2 fill:#95e1d3,color:#000,stroke:#fff,stroke-width:2px
    style Layer3 fill:#00aaff,color:#000,stroke:#fff,stroke-width:3px
    style Layer4 fill:#4ecdc4,color:#000,stroke:#fff,stroke-width:2px
    style Layer5 fill:#f38181,color:#fff,stroke:#fff,stroke-width:2px
      </div>
      
      <h3 style="color: var(--accent); margin-top: 3rem;">Security Architecture - Defense in Depth</h3>
      <p>Five-layer security model protecting all system resources</p>
      <div class="mermaid">
graph TB
    Request[Incoming Request]
    
    subgraph Layer1["ÔøΩüõ°Ô∏è Layer 1: Network Security"]
        CORS[CORS Policy]
        RateLimit[Rate Limiting]
        Firewall[Firewall Rules]
    end
    
    subgraph Layer2["üîê Layer 2: Authentication"]
        JWT[JWT Validation]
        Session[Session Check]
        Cookie[HttpOnly Cookies]
    end
    
    subgraph Layer3["üîë Layer 3: Service Auth"]
        ServiceJWT[Service-to-Service JWT]
        ReplayProt[Replay Protection]
        RequestID[Request ID Validation]
    end
    
    subgraph Layer4["üîí Layer 4: Data Encryption"]
        SQLCipher[SQLCipher AES-256]
        TLS[TLS in Transit]
        Bcrypt[Bcrypt Passwords]
    end
    
    subgraph Layer5["üë• Layer 5: RBAC"]
        Admin[Admin Role]
        UserRole[User Role]
        Permissions[Endpoint Permissions]
    end
    
    Request --> Layer1 --> Layer2 --> Layer3 --> Layer4 --> Layer5 --> Success[‚úÖ Authorized Access]
    
    Gateway[API Gateway] -.implements.-> Layer1
    Gateway -.implements.-> Layer2
    Services[Microservices] -.implement.-> Layer3
    Databases[Databases] -.implement.-> Layer4
    Endpoints[Endpoints] -.enforce.-> Layer5
    
    style Layer1 fill:#ff6b6b,color:#fff,stroke:#fff,stroke-width:2px
    style Layer2 fill:#f38181,color:#fff,stroke:#fff,stroke-width:2px
    style Layer3 fill:#aa96da,color:#fff,stroke:#fff,stroke-width:2px
    style Layer4 fill:#4ecdc4,color:#000,stroke:#fff,stroke-width:2px
    style Layer5 fill:#95e1d3,color:#000,stroke:#fff,stroke-width:2px
    style Success fill:#00aaff,color:#000,stroke:#fff,stroke-width:3px
      </div>
      
      <h3 style="color: var(--accent); margin-top: 3rem;">Function Architecture - Feature Capabilities</h3>
      <p>Functional capabilities mapped to responsible services</p>
      <div class="mermaid">
graph TB
    Input[User Input]
    
    subgraph Layer1["üé§ Layer 1: Audio Processing"]
        VAD[Voice Activity Detection]
        ASR[Speech Recognition]
        Diarization[Speaker Diarization]
    end
    
    subgraph Layer2["üß† Layer 2: AI Intelligence"]
        Emotion[Emotion Analysis<br/>6 Classes]
        LLM[Language Model<br/>Chat Responses]
        Embeddings[Text Embeddings<br/>384 Dimensions]
    end
    
    subgraph Layer3["üíæ Layer 3: Memory & Context"]
        VectorSearch[FAISS Vector Search<br/>Semantic Similarity]
        RAGRetrieval[RAG Context Retrieval<br/>Top-K Results]
        MemoryStore[Memory Storage<br/>Encrypted DB]
    end
    
    subgraph Layer4["‚öôÔ∏è Layer 4: Resource Management"]
        GPUSchedule[GPU Scheduling<br/>Pause/Resume]
        TaskQueue[Task Queueing<br/>PostgreSQL]
        PubSub[Event Messaging<br/>Redis Pub/Sub]
    end
    
    subgraph Layer5["üîå Layer 5: External Integration"]
        IoTControl[IoT Device Control<br/>VoiceMonkey]
        CloudAPI[Cloud API Fallback<br/>Deepgram/OpenAI]
        Streaming[Real-time Streaming<br/>WebSocket]
    end
    
    Input --> Layer1 --> Layer2 --> Layer3 --> Layer4 --> Layer5 --> Output[Response to User]
    
    Transcription[Transcription Service] -.provides.-> Layer1
    Emotion_Svc[Emotion Service] -.provides.-> Layer2
    Gemma_Svc[Gemma Service] -.provides.-> Layer2
    RAG_Svc[RAG Service] -.provides.-> Layer3
    Coordinator_Svc[GPU Coordinator] -.provides.-> Layer4
    Gateway_Svc[API Gateway] -.provides.-> Layer5
    
    style Layer1 fill:#4ecdc4,color:#000,stroke:#fff,stroke-width:2px
    style Layer2 fill:#95e1d3,color:#000,stroke:#fff,stroke-width:2px
    style Layer3 fill:#f38181,color:#fff,stroke:#fff,stroke-width:2px
    style Layer4 fill:#ff6b6b,color:#fff,stroke:#fff,stroke-width:2px
    style Layer5 fill:#aa96da,color:#fff,stroke:#fff,stroke-width:2px
    style Output fill:#00aaff,color:#000,stroke:#fff,stroke-width:3px
      </div>
    </div>

    <!-- DATA FLOW SECTION -->
    <div class="card">
      <h3>Microservices Data Flow</h3>
      <div class="ecosystem-flow">
        <div class="flow-step">
          <span class="num">1</span>
          <div>
            <strong>Voice Input ‚Üí API Gateway</strong> - Client (AR glasses or mobile app) sends audio to API Gateway (Port 8000)
          </div>
        </div>
        <div class="flow-step">
          <span class="num">2</span>
          <div>
            <strong>Gateway ‚Üí Transcription Service</strong> - API Gateway authenticates request and forwards to Transcription Service (Port 8003)
          </div>
        </div>
        <div class="flow-step">
          <span class="num">3</span>
          <div>
            <strong>Transcription Processing</strong> - Service performs VAD segmentation, NeMo Parakeet ASR transcription, and speaker diarization
          </div>
        </div>
        <div class="flow-step">
          <span class="num">4</span>
          <div>
            <strong>Emotion Analysis</strong> - Transcription Service sends text segments to Emotion Service (Port 8005) for sentiment detection
          </div>
        </div>
        <div class="flow-step">
          <span class="num">5</span>
          <div>
            <strong>Memory Storage</strong> - RAG Service (Port 8004) generates embeddings using MiniLM-L6-v2 and stores vectors in FAISS index
          </div>
        </div>
        <div class="flow-step">
          <span class="num">6</span>
          <div>
            <strong>Chat Request ‚Üí API Gateway</strong> - User submits chat query through API Gateway
          </div>
        </div>
        <div class="flow-step">
          <span class="num">7</span>
          <div>
            <strong>GPU Coordination</strong> - Gemma Service (Port 8001) requests GPU access from Coordinator (Port 8002)
          </div>
        </div>
        <div class="flow-step">
          <span class="num">8</span>
          <div>
            <strong>Transcription Pause</strong> - Coordinator publishes PAUSE signal via Redis Pub/Sub; Transcription acknowledges and releases GPU
          </div>
        </div>
        <div class="flow-step">
          <span class="num">9</span>
          <div>
            <strong>RAG Context Retrieval</strong> - Gemma queries RAG Service for relevant context using semantic similarity search
          </div>
        </div>
        <div class="flow-step">
          <span class="num">10</span>
          <div>
            <strong>LLM Inference</strong> - Gemma 3 4B model (Q4_K_XL quantized via llama.cpp) generates response with streaming output
          </div>
        </div>
        <div class="flow-step">
          <span class="num">11</span>
          <div>
            <strong>GPU Release & Resume</strong> - Gemma releases GPU; Coordinator signals Transcription to RESUME via Redis Pub/Sub
          </div>
        </div>
      </div>
    </div>

    <!-- API ENDPOINTS -->
    <div class="card">
      <h3>API Endpoints</h3>
      <p>All requests route through API Gateway (Port 8000) which forwards to appropriate microservices</p>
      <div class="endpoint">
        <code>POST /api/transcribe</code> ‚Üí Transcription Service (Port 8003)
        <p>Performs voice activity detection, ASR transcription, and speaker diarization on audio input</p>
      </div>
      <div class="endpoint">
        <code>POST /api/chat</code> ‚Üí Gemma Service (Port 8001)
        <p>Processes chat messages through LLM with RAG-enhanced context retrieval and GPU coordination</p>
      </div>
      <div class="endpoint">
        <code>POST /api/enroll</code> ‚Üí Transcription Service (Port 8003)
        <p>Enrolls new speaker voice profile for improved diarization accuracy</p>
      </div>
      <div class="endpoint">
        <code>POST /api/rag/index</code> ‚Üí RAG Service (Port 8004)
        <p>Indexes new documents/memories with embeddings for semantic search</p>
      </div>
      <div class="endpoint">
        <code>GET /api/rag/search</code> ‚Üí RAG Service (Port 8004)
        <p>Performs semantic similarity search across indexed memories</p>
      </div>
      <div class="endpoint">
        <code>GET /api/gpu/status</code> ‚Üí GPU Coordinator (Port 8002)
        <p>Returns current GPU allocation, active service, and pending queue status</p>
      </div>
      <div class="endpoint">
        <code>POST /api/auth/register</code> ‚Üí API Gateway (Port 8000)
        <p>User registration with bcrypt password hashing and encrypted storage</p>
      </div>
      <div class="endpoint">
        <code>POST /api/auth/login</code> ‚Üí API Gateway (Port 8000)
        <p>Authenticates user and issues JWT tokens with HttpOnly cookies</p>
      </div>
    </div>

    <!-- DESIGN DECISIONS -->
    <div class="card">
      <h3>Design Decisions</h3>
      
      <div class="feature-card">
        <h4>üîπ Microservices Over Monolith</h4>
        <p><strong>Decision:</strong> Split into 6 independent services instead of single application</p>
        <p><strong>Rationale:</strong> Enables independent scaling, isolated GPU management, better fault tolerance, and easier deployment of individual components. Each service can be updated without affecting others.</p>
        <p><strong>Trade-off:</strong> Increased complexity in orchestration and inter-service communication, but gained flexibility and scalability</p>
      </div>

      <div class="feature-card">
        <h4>üîπ Redis Pub/Sub for GPU Coordination</h4>
        <p><strong>Decision:</strong> Use Redis Pub/Sub channels for PAUSE/RESUME signals between GPU Coordinator and AI services</p>
        <p><strong>Rationale:</strong> Provides real-time, low-latency event delivery with minimal overhead. Supports multiple subscribers and ensures message delivery order. Better than HTTP polling or webhooks for this use case.</p>
        <p><strong>Trade-off:</strong> Adds Redis as infrastructure dependency, but eliminates polling overhead and reduces GPU context-switch delays</p>
      </div>

      <div class="feature-card">
        <h4>üîπ PostgreSQL Task Queue</h4>
        <p><strong>Decision:</strong> Use PostgreSQL with WAL (Write-Ahead Logging) for persistent task queue</p>
        <p><strong>Rationale:</strong> Guarantees task durability across system crashes. ACID properties ensure no task loss. Simpler than Celery/RabbitMQ for this scale.</p>
        <p><strong>Trade-off:</strong> Not as fast as in-memory queues, but acceptable for GPU coordination latency requirements (~100-200ms)</p>
      </div>

      <div class="feature-card">
        <h4>üîπ SQLCipher for Data Encryption</h4>
        <p><strong>Decision:</strong> Use SQLCipher (AES-256 encrypted SQLite) for users.db and rag.db</p>
        <p><strong>Rationale:</strong> Protects sensitive user data and memories at rest. Transparent encryption with minimal performance overhead (~5-15%). Easier than implementing application-level encryption.</p>
        <p><strong>Trade-off:</strong> Small performance cost, but critical for HIPAA/GDPR compliance and user privacy</p>
      </div>

      <div class="feature-card">
        <h4>üîπ Docker Compose Orchestration</h4>
        <p><strong>Decision:</strong> Use Docker Compose instead of Kubernetes for deployment</p>
        <p><strong>Rationale:</strong> Simpler for single-node deployment with GPU passthrough. Easier local development and testing. Less operational overhead for small-medium scale.</p>
        <p><strong>Trade-off:</strong> Limited to single-node scaling, but sufficient for current use case with 6 services on one GPU server</p>
      </div>

      <div class="feature-card">
        <h4>ÔøΩ llama.cpp for LLM Inference</h4>
        <p><strong>Decision:</strong> Use llama.cpp (0.3.16) instead of vLLM or Ollama for Gemma 3 4B</p>
        <p><strong>Rationale:</strong> Better GPU memory efficiency with Q4_K_XL quantization. Simpler integration for pause/resume cycles. Lower memory footprint (~2.8GB vs 4-6GB for FP16).</p>
        <p><strong>Trade-off:</strong> Slightly lower inference speed compared to vLLM, but acceptable for real-time chat (~15-20 tokens/sec)</p>
      </div>
    </div>

    <!-- CODE SAMPLE -->
    <div class="card">
      <h3>Code Sample - GPU Coordination Protocol</h3>
      <p>Redis Pub/Sub implementation for GPU pause/resume between Coordinator and services</p>
      <pre><code># GPU Coordinator Service (Port 8002)
class GPUCoordinator:
    async def grant_gpu_access(self, requesting_service: str):
        # 1. Publish PAUSE signal to current GPU owner
        await redis.publish(
            f"channel:{current_owner}:control",
            json.dumps({"action": "PAUSE", "request_id": uuid4()})
        )
        
        # 2. Wait for ACK with timeout
        ack = await redis.blpop(f"channel:coordinator:ack", timeout=5)
        if not ack:
            raise TimeoutError("GPU owner failed to acknowledge PAUSE")
        
        # 3. Grant GPU to requesting service
        self.current_owner = requesting_service
        await redis.publish(
            f"channel:{requesting_service}:control",
            json.dumps({"action": "GRANTED", "timestamp": time.time()})
        )
        
        # 4. Log to PostgreSQL task queue
        await db.execute(
            "INSERT INTO gpu_tasks (service, action, status) VALUES ($1, $2, $3)",
            requesting_service, "GRANT", "completed"
        )

# Transcription Service (Port 8003) - GPU Owner
class TranscriptionService:
    async def listen_for_pause(self):
        pubsub = redis.pubsub()
        await pubsub.subscribe("channel:transcription:control")
        
        async for message in pubsub.listen():
            if message["type"] == "message":
                command = json.loads(message["data"])
                if command["action"] == "PAUSE":
                    # 1. Stop current inference
                    self.pause_inference()
                    
                    # 2. Release GPU resources
                    torch.cuda.empty_cache()
                    
                    # 3. Send ACK to coordinator
                    await redis.lpush(
                        "channel:coordinator:ack",
                        json.dumps({"service": "transcription", "status": "paused"})
                    )
                    
                elif command["action"] == "RESUME":
                    # Reload models and resume processing
                    self.resume_inference()

# Gemma Service (Port 8001) - Requester
class GemmaService:
    async def request_gpu(self):
        response = await http_client.post(
            "http://gpu-coordinator:8002/api/gpu/request",
            json={"service": "gemma", "priority": "high"}
        )
        
        if response.status_code == 200:
            # Listen for GRANTED signal
            pubsub = redis.pubsub()
            await pubsub.subscribe("channel:gemma:control")
            
            async for message in pubsub.listen():
                command = json.loads(message["data"])
                if command["action"] == "GRANTED":
                    # GPU access granted, start inference
                    return await self.run_inference()
</code></pre>
    </div>

    <!-- FEATURES -->
    <div class="card">
      <h3>Key Features</h3>
      <div class="feature-grid">
        <div class="feature-card">
          <h4>üéØ Distributed Architecture</h4>
          <p>6 independent microservices orchestrated via Docker Compose with service-to-service JWT authentication</p>
        </div>
        <div class="feature-card">
          <h4>üîí Military-Grade Security</h4>
          <p>5-layer defense: Network (CORS/Rate Limit) ‚Üí Auth (JWT) ‚Üí Service Auth ‚Üí Encryption (AES-256) ‚Üí RBAC</p>
        </div>
        <div class="feature-card">
          <h4>‚ö° Smart GPU Coordination</h4>
          <p>Redis Pub/Sub-based pause/resume protocol prevents GPU memory conflicts between Transcription and Gemma services</p>
        </div>
        <div class="feature-card">
          <h4>üß† Hybrid AI Pipeline</h4>
          <p>NeMo ASR + TitaNet diarization + DistilRoBERTa emotion + Gemma 3 4B chat + FAISS vector search</p>
        </div>
        <div class="feature-card">
          <h4>üìä RAG-Enhanced Memory</h4>
          <p>Semantic search with MiniLM-L6-v2 embeddings (384-dim) and FAISS index for context-aware responses</p>
        </div>
        <div class="feature-card">
          <h4>üîê Encrypted Storage</h4>
          <p>SQLCipher databases (users.db, rag.db) with AES-256 encryption at rest + TLS 1.3 in transit</p>
        </div>
        <div class="feature-card">
          <h4>üé§ Real-time Transcription</h4>
          <p>Voice Activity Detection ‚Üí NeMo Parakeet RNNT 0.6B ASR ‚Üí Speaker diarization with TitaNet</p>
        </div>
        <div class="feature-card">
          <h4>üí¨ Streaming Chat</h4>
          <p>Gemma 3 4B (Q4_K_XL quantized) with 8K context window and ~15-20 tokens/sec inference via llama.cpp</p>
        </div>
        <div class="feature-card">
          <h4>üì° Event-Driven Design</h4>
          <p>Redis Pub/Sub for real-time GPU coordination + PostgreSQL WAL for durable task queue</p>
        </div>
        <div class="feature-card">
          <h4>ü•Ω Multi-Platform Frontend</h4>
          <p>Even Reality G1 AR glasses + Flutter mobile app + HTML/CSS/JS web dashboard</p>
        </div>
        <div class="feature-card">
          <h4>üê≥ Containerized Deployment</h4>
          <p>8 Docker containers with GPU passthrough, volume persistence, and health checks</p>
        </div>
        <div class="feature-card">
          <h4>üîç Comprehensive Logging</h4>
          <p>Structured logging with correlation IDs, error tracking, and audit trails for security events</p>
        </div>
      </div>
    </div>

    <!-- PRODUCTION READINESS -->
    <div class="card">
      <h3>Production Readiness</h3>
      <ul>
        <li><strong>Security Hardened:</strong> CORS policies, JWT authentication, rate limiting, SQLCipher encryption, bcrypt passwords, RBAC</li>
        <li><strong>Error Handling:</strong> Comprehensive try-catch blocks, graceful degradation, timeout handling, retry logic with exponential backoff</li>
        <li><strong>Monitoring:</strong> Health check endpoints on all services, GPU status monitoring, Redis connection pooling, PostgreSQL query logging</li>
        <li><strong>Scalability:</strong> Horizontal scaling ready for API Gateway and stateless services; vertical scaling for GPU-bound services</li>
        <li><strong>Deployment:</strong> Docker Compose with volume persistence, environment variable configuration, secrets management</li>
        <li><strong>Documentation:</strong> Comprehensive ARCHITECTURE.md, API documentation, deployment guides, troubleshooting docs</li>
        <li><strong>Testing:</strong> Unit tests, integration tests, smoke tests, GPU coordination stress tests, security audit scripts</li>
        <li><strong>Performance:</strong> GPU coordination latency ~100-200ms, transcription real-time factor ~0.3x, chat inference ~15-20 tok/sec</li>
      </ul>
    </div>

  </div>

  <footer>
    <p>Built with ‚ù§Ô∏è for distributed AI systems ‚Ä¢ <a href="https://github.com/pruittcolon">GitHub</a> ‚Ä¢ <a href="mailto:pruitt@example.com">Contact</a></p>
  </footer>

  <script>
    const nav = document.getElementById('navbar');
    const navLinks = document.getElementById('nav-links');
    const toggleBtn = document.getElementById('menu-toggle');

    const closeMenu = () => {
      navLinks.classList.remove('open');
      document.body.classList.remove('nav-open');
      toggleBtn.setAttribute('aria-expanded', 'false');
      toggleBtn.setAttribute('aria-label', 'Open navigation');
    };

    toggleBtn.addEventListener('click', () => {
      const isOpen = navLinks.classList.toggle('open');
      document.body.classList.toggle('nav-open', isOpen);
      toggleBtn.setAttribute('aria-expanded', String(isOpen));
      toggleBtn.setAttribute('aria-label', isOpen ? 'Close navigation' : 'Open navigation');
    });

    navLinks.querySelectorAll('a').forEach(link => link.addEventListener('click', closeMenu));

    window.addEventListener('resize', () => {
      if (window.innerWidth > 720) {
        closeMenu();
      }
    });

    window.addEventListener('scroll', () => {
      nav.classList.toggle('scrolled', window.scrollY > 60);
    });

    nav.classList.toggle('scrolled', window.scrollY > 60);
  </script>

  <!-- Mermaid.js -->
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: 'dark',
      themeVariables: {
        primaryColor: '#00aaff',
        primaryTextColor: '#fff',
        primaryBorderColor: '#00aaff',
        lineColor: '#00aaff',
        secondaryColor: '#1a1f2e',
        tertiaryColor: '#0c0e11',
        background: '#0c0e11',
        mainBkg: '#1a1f2e',
        textColor: '#f0f6ff',
        fontSize: '16px'
      },
      flowchart: {
        htmlLabels: true,
        curve: 'basis',
        padding: 20
      }
    });
  </script>

  <!-- Particle.js -->
  <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
  <script>
    particlesJS("particles-js", {
      particles: {
        number: { value: 80, density: { enable: true, value_area: 800 } },
        color: { value: "#00aaff" },
        shape: { type: "circle" },
        opacity: { value: 0.5, random: false },
        size: { value: 3, random: true },
        line_linked: { enable: true, distance: 150, color: "#00aaff", opacity: 0.4, width: 1 },
        move: { enable: true, speed: 2, direction: "none", random: false, straight: false, out_mode: "out", bounce: false }
      },
      interactivity: {
        detect_on: "canvas",
        events: { onhover: { enable: true, mode: "repulse" }, onclick: { enable: true, mode: "push" }, resize: true },
        modes: { repulse: { distance: 100, duration: 0.4 }, push: { particles_nb: 4 } }
      },
      retina_detect: true
    });
  </script>

</body>
</html>
